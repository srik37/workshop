{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving a TensorFlow Model as a REST Endpoint with TensorFlow Serving and SageMaker\n",
    "\n",
    "We need to understand the application and business context to choose between real-time and batch predictions. Are we trying to optimize for latency or throughput? Does the application require our models to scale automatically throughout the day to handle cyclic traffic requirements? Do we plan to compare models in production through A/B tests?\n",
    "\n",
    "If our application requires low latency, then we should deploy the model as a real-time API to provide super-fast predictions on single prediction requests over HTTPS. We can deploy, scale, and compare our model prediction servers with SageMaker Endpoints.\n",
    "\n",
    "## Interesting Reads\n",
    "* [**How Roblox Scaled BERT to Serve 1+ Billion Daily Requests on CPUs**](https://blog.roblox.com/2020/05/scaled-bert-serve-1-billion-daily-requests-cpus/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/sagemaker-architecture.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    training_job_name\n",
    "    print('[OK]')\n",
    "except NameError:\n",
    "    print('+++++++++++++++++++++++++++++++')\n",
    "    print('[ERROR] Please run the notebooks in the previous TRAIN section before you continue.')\n",
    "    print('+++++++++++++++++++++++++++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-training-2020-09-26-18-44-25-975\n"
     ]
    }
   ],
   "source": [
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy the Model to the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-085964654406/tensorflow-training-2020-09-26-18-44-25-975/output/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz ./model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers/\n",
      "transformers/fine-tuned/\n",
      "transformers/fine-tuned/tf_model.h5\n",
      "transformers/fine-tuned/config.json\n",
      "tensorflow/\n",
      "tensorflow/saved_model/\n",
      "tensorflow/saved_model/0/\n",
      "tensorflow/saved_model/0/variables/\n",
      "tensorflow/saved_model/0/variables/variables.index\n",
      "tensorflow/saved_model/0/variables/variables.data-00000-of-00001\n",
      "tensorflow/saved_model/0/assets/\n",
      "tensorflow/saved_model/0/saved_model.pb\n",
      "code/\n",
      "code/inference.py\n",
      "tensorboard/\n",
      "metrics/\n",
      "metrics/confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./model/\n",
    "!tar -xvzf ./model.tar.gz -C ./model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-26 20:12:49.848844: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/extras/CUPTI/lib64:/usr/local/cuda-10.0/lib:/usr/local/cuda-10.0/efa/lib:/opt/amazon/efa/lib:/opt/amazon/efa/lib64:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:\n",
      "2020-09-26 20:12:49.848926: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/extras/CUPTI/lib64:/usr/local/cuda-10.0/lib:/usr/local/cuda-10.0/efa/lib:/opt/amazon/efa/lib:/opt/amazon/efa/lib64:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:\n",
      "2020-09-26 20:12:49.848938: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_ids'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 64)\n",
      "        name: serving_default_input_ids:0\n",
      "    inputs['input_mask'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 64)\n",
      "        name: serving_default_input_mask:0\n",
      "    inputs['segment_ids'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 64)\n",
      "        name: serving_default_segment_ids:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 5)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/segment_ids'), 'input_mask': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 64), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 64), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/segment_ids'), 'input_mask': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 64), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='input_ids')}\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 64), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 64), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/segment_ids'), 'input_mask': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/segment_ids'), 'input_mask': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 64), dtype=tf.int64, name='inputs/input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --all --dir ./model/tensorflow/saved_model/0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show `inference.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "subprocess.check_call([sys.executable, \u001b[33m'\u001b[39;49;00m\u001b[33m-m\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mpip\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33minstall\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtensorflow==2.1.0\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "subprocess.check_call([sys.executable, \u001b[33m'\u001b[39;49;00m\u001b[33m-m\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mpip\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33minstall\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtransformers==2.8.0\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DistilBertTokenizer\n",
      "\n",
      "classes=[\u001b[34m1\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m, \u001b[34m4\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m]\n",
      "\n",
      "max_seq_length=\u001b[34m64\u001b[39;49;00m\n",
      "\n",
      "tokenizer = DistilBertTokenizer.from_pretrained(\u001b[33m'\u001b[39;49;00m\u001b[33mdistilbert-base-uncased\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_handler\u001b[39;49;00m(data, context):\n",
      "    transformed_instances = []\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mDATA \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(data))\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m instance \u001b[35min\u001b[39;49;00m data:\n",
      "        data_str = instance.decode(\u001b[33m'\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mDATA_STR \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(data_str))\n",
      "        \n",
      "        tokens = tokenizer.tokenize(data_str)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mTOKENS \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(tokens))\n",
      "\n",
      "        encode_plus_tokens = tokenizer.encode_plus(data_str,\n",
      "                                                   pad_to_max_length=\u001b[34mTrue\u001b[39;49;00m,\n",
      "                                                   max_length=max_seq_length,\n",
      "\u001b[37m#                                                   truncation=True\u001b[39;49;00m\n",
      "                                                  )\n",
      "\n",
      "        \u001b[37m# Convert the text-based tokens to ids from the pre-trained BERT vocabulary\u001b[39;49;00m\n",
      "        input_ids = encode_plus_tokens[\u001b[33m'\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "        \u001b[37m# Specifies which tokens BERT should pay attention to (0 or 1)\u001b[39;49;00m\n",
      "        input_mask = encode_plus_tokens[\u001b[33m'\u001b[39;49;00m\u001b[33mattention_mask\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "        \u001b[37m# Segment Ids are always 0 for single-sequence tasks (or 1 if two-sequence tasks)\u001b[39;49;00m\n",
      "        segment_ids = [\u001b[34m0\u001b[39;49;00m] * max_seq_length\n",
      "    \n",
      "        transformed_instance = { \n",
      "                                 \u001b[33m\"\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: input_ids, \n",
      "                                 \u001b[33m\"\u001b[39;49;00m\u001b[33minput_mask\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: input_mask, \n",
      "                                 \u001b[33m\"\u001b[39;49;00m\u001b[33msegment_ids\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: segment_ids\n",
      "                               }\n",
      "    \n",
      "        transformed_instances.append(transformed_instance)\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(transformed_instances)\n",
      "    \n",
      "    transformed_data = {\u001b[33m\"\u001b[39;49;00m\u001b[33minstances\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: transformed_instances}\n",
      "    \u001b[36mprint\u001b[39;49;00m(transformed_data)\n",
      "\n",
      "    transformed_data_json = json.dumps(transformed_data)\n",
      "    \u001b[36mprint\u001b[39;49;00m(transformed_data_json)\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m transformed_data_json\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_handler\u001b[39;49;00m(response, context):\n",
      "    response_json = response.json()\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mresponse_json: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(response_json))\n",
      "    \n",
      "    log_probabilities = response_json[\u001b[33m\"\u001b[39;49;00m\u001b[33mpredictions\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "\n",
      "    predicted_classes = []\n",
      "\n",
      "    \u001b[34mfor\u001b[39;49;00m log_probability \u001b[35min\u001b[39;49;00m log_probabilities:\n",
      "        softmax = tf.nn.softmax(log_probability)    \n",
      "        predicted_class_idx = tf.argmax(softmax, axis=-\u001b[34m1\u001b[39;49;00m, output_type=tf.int32)\n",
      "        predicted_class = classes[predicted_class_idx]\n",
      "        predicted_classes.append(predicted_class)\n",
      "    \n",
      "    predicted_classes_json = json.dumps(predicted_classes)    \n",
      "    \u001b[36mprint\u001b[39;49;00m(predicted_classes_json)\n",
      "\n",
      "    response_content_type = context.accept_header\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m predicted_classes_json, response_content_type\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ./model/code/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the Model\n",
    "This will create a default `EndpointConfig` with a single model.  \n",
    "\n",
    "The next notebook will demonstrate how to perform more advanced `EndpointConfig` strategies to support canary rollouts and A/B testing.\n",
    "\n",
    "_Note:  If not using a US-based region, you may need to adapt the container image to your current region using the following table:_\n",
    "\n",
    "https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-training-2020-09-26-18-44-25-975-tf-1601151176\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "tensorflow_model_name = '{}-{}-{}'.format(training_job_name, 'tf', timestamp)\n",
    "\n",
    "print(tensorflow_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "\n",
    "tensorflow_model = TensorFlowModel(name=tensorflow_model_name,\n",
    "                                   model_data='s3://{}/{}/output/model.tar.gz'.format(bucket, training_job_name),\n",
    "                                   role=role,                \n",
    "                                   framework_version='2.1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-training-2020-09-26-18-44-25-975-tf-1601151176\n"
     ]
    }
   ],
   "source": [
    "tensorflow_endpoint_name = '{}-{}-{}'.format(training_job_name, 'tf', timestamp)\n",
    "\n",
    "print(tensorflow_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow_model = tensorflow_model.deploy(endpoint_name=tensorflow_endpoint_name,\n",
    "                                           initial_instance_count=1, # Should use >=2 for high(er) availability \n",
    "                                           instance_type='ml.m5.4xlarge', # requires enough disk space for tensorflow, transformers, and bert downloads\n",
    "                                           wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-west-2#/endpoints/tensorflow-training-2020-09-26-18-44-25-975-tf-1601151176\">SageMaker REST Endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(region, tensorflow_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Wait Until the Endpoint is Deployed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 140 ms, sys: 11.7 ms, total: 151 ms\n",
      "Wall time: 6min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=tensorflow_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Wait Until the ^^ Endpoint ^^ is Deployed_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.model import TensorFlowPredictor\n",
    "\n",
    "predictor = TensorFlowPredictor(endpoint_name=tensorflow_endpoint_name,\n",
    "                                sagemaker_session=sess,\n",
    "                                model_name='saved_model',\n",
    "                                model_version=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting for the Endpoint to be ready to Serve Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the `star_rating` with Ad Hoc `review_body` Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Predicted Star Rating: 5] This is great!\n"
     ]
    }
   ],
   "source": [
    "reviews = [\"This is great!\"]\n",
    "\n",
    "predicted_classes = predictor.predict(reviews)\n",
    "\n",
    "for predicted_class, review in zip(predicted_classes, reviews):\n",
    "    print('[Predicted Star Rating: {}]'.format(predicted_class), review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the `star_rating` with `review_body` Samples from our TSV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "df_reviews = pd.read_csv('./data/amazon_reviews_us_Digital_Software_v1_00.tsv.gz', \n",
    "                         delimiter='\\t', \n",
    "                         quoting=csv.QUOTE_NONE,\n",
    "                         compression='gzip')\n",
    "df_sample_reviews = df_reviews[['review_body', 'star_rating']].sample(n=100)\n",
    "df_sample_reviews = df_sample_reviews.reset_index()\n",
    "df_sample_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47054</td>\n",
       "      <td>Exactly what was advertized.</td>\n",
       "      <td>5</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76847</td>\n",
       "      <td>After reading all the bad reviews I still boug...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51770</td>\n",
       "      <td>I feel its the best free one out there!</td>\n",
       "      <td>5</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20692</td>\n",
       "      <td>Does the job.</td>\n",
       "      <td>5</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99422</td>\n",
       "      <td>IF YOU ARE SMART, YOU WILL JUST BUY THE DISKS!...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        review_body  star_rating  \\\n",
       "0  47054                       Exactly what was advertized.            5   \n",
       "1  76847  After reading all the bad reviews I still boug...            1   \n",
       "2  51770            I feel its the best free one out there!            5   \n",
       "3  20692                                      Does the job.            5   \n",
       "4  99422  IF YOU ARE SMART, YOU WILL JUST BUY THE DISKS!...            1   \n",
       "\n",
       "  predicted_class  \n",
       "0             [3]  \n",
       "1             [1]  \n",
       "2             [5]  \n",
       "3             [5]  \n",
       "4             [1]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict(review_body):\n",
    "    return predictor.predict(review_body)\n",
    "\n",
    "df_sample_reviews['predicted_class'] = df_sample_reviews['review_body'].map(predict)\n",
    "df_sample_reviews.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save for Next Notebook(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'tensorflow_model_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store tensorflow_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'tensorflow_endpoint_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store tensorflow_endpoint_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "auto_ml_job_name                                      -> 'automl-dm-26-16-00-25'\n",
      "autopilot_endpoint_name                               -> 'automl-dm-ep-26-16-21-49'\n",
      "autopilot_train_s3_uri                                -> 's3://sagemaker-us-west-2-085964654406/data/amazon\n",
      "balance_dataset                                       -> True\n",
      "experiment_name                                       -> 'Amazon-Customer-Reviews-BERT-Experiment-160114585\n",
      "ingest_create_athena_db_passed                        -> True\n",
      "ingest_create_athena_table_parquet_passed             -> True\n",
      "ingest_create_athena_table_tsv_passed                 -> True\n",
      "max_seq_length                                        -> 64\n",
      "prepare_trial_component_name                          -> 'TrialComponent-2020-09-26-184417-oahc'\n",
      "processed_test_data_s3_uri                            -> 's3://sagemaker-us-west-2-085964654406/sagemaker-s\n",
      "processed_train_data_s3_uri                           -> 's3://sagemaker-us-west-2-085964654406/sagemaker-s\n",
      "processed_validation_data_s3_uri                      -> 's3://sagemaker-us-west-2-085964654406/sagemaker-s\n",
      "pytorch_model_name                                    -> 'tensorflow-training-2020-09-26-18-44-25-975-pt-16\n",
      "raw_input_data_s3_uri                                 -> 's3://sagemaker-us-west-2-085964654406/amazon-revi\n",
      "s3_private_path_tsv                                   -> 's3://sagemaker-us-west-2-085964654406/amazon-revi\n",
      "s3_public_path_tsv                                    -> 's3://amazon-reviews-pds/tsv'\n",
      "setup_dependencies_passed                             -> True\n",
      "setup_iam_roles_passed                                -> True\n",
      "setup_instance_check_passed                           -> True\n",
      "setup_s3_bucket_passed                                -> True\n",
      "tensorflow_endpoint_name                              -> 'tensorflow-training-2020-09-26-18-44-25-975-tf-16\n",
      "tensorflow_model_name                                 -> 'tensorflow-training-2020-09-26-18-44-25-975-tf-16\n",
      "test_split_percentage                                 -> 0.05\n",
      "train_split_percentage                                -> 0.9\n",
      "training_job_debugger_artifacts_path                  -> 's3://sagemaker-us-west-2-085964654406/tensorflow-\n",
      "training_job_name                                     -> 'tensorflow-training-2020-09-26-18-44-25-975'\n",
      "transformer_pytorch_model_name                        -> 'pytorch_model.bin'\n",
      "transformer_pytorch_model_s3_uri                      -> 's3://sagemaker-us-west-2-085964654406/models/tran\n",
      "trial_name                                            -> 'trial-1601145857'\n",
      "tuning_job_name                                       -> 'tensorflow-training-200926-1943'\n",
      "validation_split_percentage                           -> 0.05\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Endpoint\n",
    "To save cost, we should delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.delete_endpoint(\n",
    "#      EndpointName=tensorflow_endpoint_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.save_checkpoint();\n",
       "Jupyter.notebook.session.delete();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.save_checkpoint();\n",
    "Jupyter.notebook.session.delete();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
